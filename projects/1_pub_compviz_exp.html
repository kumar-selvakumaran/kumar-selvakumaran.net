<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Computer Vision Explainability in Safety Surveillance | Kumar Selvakumaran </title> <meta name="author" content="Kumar Selvakumaran"> <meta name="description" content="An explainability framework for safety surveillance, extending Eigen-CAM to YOLOv5 object detection with relevance-based layer selection for bias diagnosis."> <link rel="stylesheet" href="/website/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/website/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/website/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/website/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%93&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/website/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="/website/projects/1_pub_compviz_exp.html"> <script src="/website/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/website/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/website/"> <span class="font-weight-bold">Kumar</span> Selvakumaran </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/website/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/website/projects_and_publications/">Projects and publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/website/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Computer Vision Explainability in Safety Surveillance</h1> <p class="post-description">An explainability framework for safety surveillance, extending Eigen-CAM to YOLOv5 object detection with relevance-based layer selection for bias diagnosis.</p> </header> <article> <p><a href="https://github.com/kumar-selvakumaran/explainable_hardhat_detection" rel="external nofollow noopener" target="_blank">Github repoðŸ”—</a></p> <p><a href="https://link.springer.com/chapter/10.1007/978-981-99-0838-7_21" rel="external nofollow noopener" target="_blank">Publication linkðŸ”—</a></p> <p><strong>What is this project about?</strong></p> <p>This project explores how <strong>Eigen-CAM</strong> can be applied to <strong>YOLOv5 object detection</strong> to improve explainability in <strong>safety-critical environments</strong>. In particular, it focuses on <strong>hardhat detection in construction surveillance</strong>, where accuracy and trust are vital.</p> <ul> <li> <p><strong>Goal</strong>:</p> <ol> <li>Explain YOLOv5â€™s predictions using <strong>Eigen-CAM heatmaps</strong>.</li> <li>Diagnose whether the model relies on the <strong>right visual features</strong> (hardhat surface vs. irrelevant cues like faces/background).</li> <li>Introduce a <strong>relevance-based layer selection strategy</strong> to refine explanations for object detection.</li> </ol> </li> </ul> <hr> <h3 id="problem-approach">Problem Approach</h3> <ul> <li>Modern CNNs (like YOLOv5) are powerful but opaque: their predictions are often <strong>black boxes</strong>.</li> <li>Existing explainability techniques (Grad-CAM, SmoothGrad, etc.) are <strong>gradient-based</strong> and mainly suited for classification.</li> <li> <strong>Eigen-CAM</strong> is different: it is a <strong>gradient-free</strong> method that uses <strong>singular value decomposition (SVD)</strong> on convolutional activations to extract dominant visual features.</li> <li> <p>This project extends Eigen-CAM by:</p> <ul> <li>Ranking YOLOv5 layers with a <strong>relevance score</strong> (inside vs. outside bounding boxes).</li> <li>Averaging the most relevant layers to produce sharper, more task-specific explanations.</li> </ul> </li> </ul> <hr> <h3 id="methodology">Methodology</h3> <ol> <li> <p><strong>Detection Module</strong></p> <ul> <li>Use YOLOv5 to detect objects in a given image.</li> </ul> </li> <li> <p><strong>Activation Extraction (Eigen-CAM)</strong></p> <ul> <li>Collect activation maps from convolutional layers.</li> <li>Apply <strong>SVD</strong> to extract the first principal component â†’ Eigen-CAM saliency map.</li> </ul> </li> <li> <p><strong>Relevance-Based Layer Selection (Project Contribution)</strong></p> <ul> <li>Compute a <strong>relevance score</strong> = ratio of activations inside bounding boxes vs. outside.</li> <li>Rank layers by this score and select the top layers.</li> <li>Average these layersâ€™ Eigen-CAM maps for the final explanation.</li> </ul> </li> <li> <p><strong>Visualization</strong></p> <ul> <li>Overlay Eigen-CAM maps on the original image to see <strong>which regions drive YOLOv5â€™s detections</strong>.</li> </ul> </li> </ol> <hr> <h3 id="applications-safety-surveillance">Applications: Safety Surveillance</h3> <ul> <li> <strong>Hardhat Detection</strong> â€“ Verify the modelâ€™s focus is truly on the hardhat, not worker faces or background noise.</li> <li> <strong>Bias Diagnosis</strong> â€“ Detect when a model relies on spurious features (e.g., skin tone, shadows, clothing).</li> <li> <strong>Industrial Monitoring</strong> â€“ Improve trust in AI systems deployed in <strong>construction sites, factories, and surveillance networks</strong>.</li> </ul> <hr> <h3 id="why-this-approach-is-better">Why This Approach is Better</h3> <ul> <li> <p><strong>Eigen-CAM Strengths</strong></p> <ul> <li>Gradient-free â†’ more stable than gradient-based methods.</li> <li>Works with detection models without retraining or modifying the architecture.</li> <li>Robust to misclassification: heatmaps arenâ€™t tied to the predicted class score.</li> </ul> </li> <li> <p><strong>Project Extension</strong></p> <ul> <li> <strong>Relevance-based layer selection</strong> makes explanations more precise for object detection.</li> <li>Ensures <strong>location-specific insights</strong> by focusing on activations inside bounding boxes.</li> </ul> </li> </ul> <hr> <h3 id="findings">Findings</h3> <ul> <li>Eigen-CAM revealed when YOLOv5 correctly focused on hardhat regions â†’ unbiased detection.</li> <li>It also exposed <strong>failure cases</strong>, where predictions were driven by irrelevant features.</li> <li>In benchmark comparisons, <strong>Eigen-CAM produced lower error rates</strong> than Grad-CAM variants for weakly supervised localization tasks.</li> </ul> <hr> <h3 id="deliverables">Deliverables</h3> <ul> <li> <strong>YOLOv5 + Eigen-CAM explainability pipeline</strong>.</li> <li> <strong>Relevance-based layer selection module</strong> for object detection.</li> <li> <strong>Visualization toolkit</strong> to generate human-interpretable explanations.</li> </ul> <hr> <h3 id="impact--implications">Impact &amp; Implications</h3> <ul> <li> <strong>For safety-critical AI</strong>: Ensures models are transparent and trustworthy.</li> <li> <strong>For dataset curation</strong>: Helps reveal bias, guiding dataset improvements.</li> <li> <strong>For explainable AI research</strong>: Demonstrates how <strong>Eigen-CAM + relevance scoring</strong> can extend explainability into object detection tasks.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/website/assets/img/project_imgs/explainable_hardhat_detection-480.webp 480w,/website/assets/img/project_imgs/explainable_hardhat_detection-800.webp 800w,/website/assets/img/project_imgs/explainable_hardhat_detection-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/website/assets/img/project_imgs/explainable_hardhat_detection.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="visualization of automatated EigenCAM explanations" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Eigen-CAM explanations for YOLOv5 hardhat detection: the first column shows detections, the middle two columns display saliency maps from the top three most relevant layers, and the final column presents the averaged heatmaps highlighting where the model focuses for predictions. </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2025 Kumar Selvakumaran. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/website/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/website/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/website/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/website/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/website/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/website/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/website/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/website/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/website/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/website/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/website/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/website/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/website/assets/js/search-data.js"></script> <script src="/website/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>