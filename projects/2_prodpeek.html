<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Single-Shot Localized Retrieval using YOLOv3 | Kumar Selvakumaran </title> <meta name="author" content="Kumar Selvakumaran"> <meta name="description" content="A retrieval system that takes object selections as bounding box prompts from the user, given an image and retrievs similar objects from an image database."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%93&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="kumar-selvakumaran.github.io/projects/2_prodpeek.html"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Kumar</span> Selvakumaran </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects_and_publications/">Projects and publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Single-Shot Localized Retrieval using YOLOv3</h1> <p class="post-description">A retrieval system that takes object selections as bounding box prompts from the user, given an image and retrievs similar objects from an image database.</p> </header> <article> <p><a href="https://github.com/kumar-selvakumaran/RobAn_veriml" rel="external nofollow noopener" target="_blank">Github repoüîó</a></p> <p><strong>What is this project about?</strong></p> <p>This project explores how <strong>neural networks can be used for content-based image retrieval (CBIR)</strong> ‚Äî finding visually similar objects based on features learned by an object detection network. Instead of classifying images into rigid categories (dog vs. cat), this system extracts object-specific embeddings and uses them for <strong>similarity search and recommendations</strong>.</p> <ul> <li> <strong>Goal</strong>: Enable search, grouping, and recommendation of objects by visual features such as <strong>size, texture, color, and style</strong> ‚Äî especially in <strong>product cataloguing contexts</strong> where users look for items that ‚Äúlook like this one.‚Äù</li> </ul> <hr> <h3 id="problem-approach">Problem Approach</h3> <ul> <li> <strong>Traditional retrieval methods</strong> often rely on multi-step processes: first isolating an object manually, then extracting features in a separate step, and finally performing similarity search.</li> <li> <p>This project makes retrieval more <strong>efficient and scalable</strong> by using a <strong>single forward pass of the detection network</strong> to:</p> <ul> <li>Detect objects,</li> <li>Extract embeddings,</li> <li>And slice features for the chosen object.</li> </ul> </li> </ul> <p>This means <strong>location-specific retrieval happens in one step</strong>, avoiding the inefficiency of multi-stage pipelines.</p> <hr> <h3 id="methodology">Methodology</h3> <ol> <li> <p><strong>Detect Objects</strong></p> <ul> <li>Run the image through an object detector to get bounding boxes.</li> </ul> </li> <li> <p><strong>Extract Features (Embeddings)</strong></p> <ul> <li>Collect feature maps from the detection backbone (e.g., ResNet, YOLO).</li> </ul> </li> <li> <p><strong>Object-Specific Slicing</strong></p> <ul> <li>Slice embeddings according to object location to isolate <strong>features for the chosen object</strong>.</li> </ul> </li> <li> <p><strong>Similarity Search</strong></p> <ul> <li>Compare the chosen object‚Äôs features against a pre-computed dataset using KNN.</li> </ul> </li> <li> <p><strong>Retrieve Matches</strong></p> <ul> <li>Return images ranked by similarity ‚Äî highlighting visual attributes like <strong>color, texture, and lighting</strong>.</li> </ul> </li> </ol> <hr> <h3 id="applications-product-cataloguing">Applications: Product Cataloguing</h3> <ul> <li> <strong>Furniture Catalogs</strong> ‚Äì A customer highlights a couch in a cluttered image; the system retrieves <strong>visually similar couches</strong> from the database.</li> <li> <strong>E-commerce Product Discovery</strong> ‚Äì Group or recommend products by shared visual features (color, texture, style).</li> <li> <strong>Automated Curation</strong> ‚Äì Streamline catalog management by automatically clustering products with similar aesthetics.</li> </ul> <p>This workflow enables <strong>fast, accurate, and context-aware cataloguing</strong>, reducing the manual effort usually required for tagging or categorization.</p> <hr> <h3 id="why-this-approach-is-better">Why This Approach is Better</h3> <ul> <li> <strong>Single-Shot Retrieval</strong>: The object detection network simultaneously handles object localization and feature extraction.</li> <li> <strong>Efficiency</strong>: Unlike multi-step methods that require separate processes for detection and embedding, this workflow performs <strong>location-specific retrieval directly</strong> from the detection backbone.</li> <li> <strong>Scalability</strong>: The system is well-suited for large product catalogues, where speed and automation are critical.</li> </ul> <hr> <h3 id="findings">Findings</h3> <p>Experiments show that the network captures rich object features:</p> <ul> <li> <strong>Color and Texture</strong> (e.g., fabric, material)</li> <li><strong>Shape and Size</strong></li> <li><strong>Appearance under lighting</strong></li> </ul> <p>These embeddings make similarity search and recommendation <strong>practical and accurate</strong>, even in visually diverse datasets.</p> <hr> <h3 id="deliverables">Deliverables</h3> <ul> <li> <strong>Feature extraction pipeline</strong> (ResNet / YOLO embeddings).</li> <li> <strong>KNN-based similarity search</strong> on pre-computed object embeddings.</li> <li> <strong>Visualization experiments</strong> of targets vs. retrieved matches.</li> </ul> <hr> <h3 id="impact--implications">Impact &amp; Implications</h3> <ul> <li> <strong>For product cataloguing</strong>: Simplifies grouping, tagging, and discovery of items with shared features.</li> <li> <strong>For users</strong>: Enables intuitive ‚Äúfind me more like this‚Äù search.</li> <li> <strong>For research</strong>: Extends CBIR from classification-based to <strong>object-detection‚Äìbased retrieval</strong> with efficiency gains.</li> </ul> <hr> <h3 id="development-setup">Development Setup</h3> <ul> <li> <strong>OS</strong>: Windows 11 with Docker (WSL2, Ubuntu 22.04)</li> <li> <strong>Docker desktop</strong>: v4.22.1</li> <li> <strong>Docker version</strong>: 24.0.5</li> <li> <strong>Compiler</strong>: Python 3.7</li> </ul> <hr> <h3 id="run-instructions">Run Instructions</h3> <p>Go through the following notebooks to reproduce the workflow:</p> <ol> <li><a href="https://github.com/kumar-selvakumaran/semantic_product_catalogue_assistant/blob/main/src/init_setup.ipynb" rel="external nofollow noopener" target="_blank">init_setup.ipynb</a></li> <li><a href="https://github.com/kumar-selvakumaran/semantic_product_catalogue_assistant/blob/main/src/Resnet_embedding_collector.ipynb" rel="external nofollow noopener" target="_blank">Resnet_embedding_collector.ipynb</a></li> <li><a href="https://github.com/kumar-selvakumaran/semantic_product_catalogue_assistant/blob/main/src/embedding_KNN_analyzer.ipynb" rel="external nofollow noopener" target="_blank">embedding_KNN_analyzer.ipynb</a></li> <li><a href="https://github.com/kumar-selvakumaran/semantic_product_catalogue_assistant/blob/main/src/Yolo_embedding_collector.ipynb" rel="external nofollow noopener" target="_blank">Yolo_embedding_collector.ipynb</a></li> <li><a href="https://github.com/kumar-selvakumaran/semantic_product_catalogue_assistant/blob/main/src/Location_information_analysis.ipynb" rel="external nofollow noopener" target="_blank">Location_information_analysis.ipynb</a></li> </ol> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_imgs/prodseek_workflow-480.webp 480w,/assets/img/project_imgs/prodseek_workflow-800.webp 800w,/assets/img/project_imgs/prodseek_workflow-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/project_imgs/prodseek_workflow.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="prodseek_workflow" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> This figure visualizes the workflow of the retrieval pipeline. </div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project_imgs/local_retrieval_masking-480.webp 480w,/assets/img/project_imgs/local_retrieval_masking-800.webp 800w,/assets/img/project_imgs/local_retrieval_masking-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/project_imgs/local_retrieval_masking.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="local_retrieval_masking" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> This figure visualizes how localized retrieval is done in the latent space of the yolov3 model. each channel selection in the spatial embedding grid corresponds to a crop in the input image, as shown in the figure. The yellow grid surrounded (surrounded by the blue) is the spatial embedding selection, and the corresponding crop is indicated using the black bounding box. </div> </article> <h2>References</h2> <div class="publications"> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Kumar Selvakumaran. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>